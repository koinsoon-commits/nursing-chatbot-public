import os
import json
import streamlit as st
from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain_classic.chains import create_retrieval_chain
from langchain_classic.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate
import gspread
from datetime import datetime
import pytz

# 1. API í‚¤ ì„¤ì • (ìŠ¤íŠ¸ë¦¼ë¦¿ ê¸ˆê³ ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]

# Streamlit ì›¹ í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì„±ì¸ê°„í˜¸í•™ AI íŠœí„°", page_icon="ğŸ¥")
st.title("ğŸ¥ ì„±ì¸ê°„í˜¸í•™ AI íŠœí„°")
st.markdown(
    "ê°•ì˜ë¡ê³¼ ì‹¤ë¼ë²„ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ ë“œë¦½ë‹ˆë‹¤. ëª¨í˜¸í•œ ë‚´ìš©ì€ êµìˆ˜ë‹˜ê»˜ ë¬¸ì˜í•˜ë„ë¡ ì•ˆë‚´í•©ë‹ˆë‹¤."
)


# 2. êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—°ê²° ì„¤ì • (ìŠ¤íŠ¸ë¦¼ë¦¿ ê¸ˆê³  ì‚¬ìš©)
@st.cache_resource
def init_google_sheet():
    try:
        # ìŠ¤íŠ¸ë¦¼ë¦¿ ê¸ˆê³ ì— ìˆ¨ê²¨ë‘” êµ¬ê¸€ í‚¤(JSON)ë¥¼ íŒŒì´ì¬ ì‚¬ì „ í˜•íƒœë¡œ ë³€í™˜í•´ì„œ ì½ê¸°
        google_secret_str = st.secrets["GOOGLE_SECRET"]
        creds_dict = json.loads(google_secret_str)
        gc = gspread.service_account_from_dict(creds_dict)

        sh = gc.open("ì±—ë´‡_ì§ˆë¬¸ê¸°ë¡")  # êµìˆ˜ë‹˜ ì—‘ì…€ íŒŒì¼ëª…
        worksheet = sh.sheet1

        if len(worksheet.get_all_values()) == 0:
            worksheet.append_row(["ì‹œê°„", "í•™ìƒ ì§ˆë¬¸", "AI íŠœí„° ë‹µë³€"])

        return worksheet
    except Exception as e:
        st.warning(f"âš ï¸ êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì—ëŸ¬ ì›ì¸:{e}")
        return None


sheet = init_google_sheet()


# 3. RAG íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
@st.cache_resource
def init_rag_pipeline():
    loader = PyPDFDirectoryLoader("data")
    docs = loader.load()

    if not docs:
        return None

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents(docs)

    vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings())
    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

    system_prompt = """
    [ì—­í•  ë° í˜ë¥´ì†Œë‚˜]
    ë‹¹ì‹ ì€ ê°„í˜¸ëŒ€í•™ìƒì˜ 'ì„±ì¸ê°„í˜¸í•™(Adult Nursing)' í•™ìŠµ ë° êµê³¼ëª© ì´ìˆ˜ë¥¼ ë•ëŠ” ì „ë¬¸ì ì´ê³  ì •í™•í•œ AI íŠœí„° ì±—ë´‡ì…ë‹ˆë‹¤. í•™ìƒì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  í•™êµ¬ì ì¸ íƒœë„ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.

    [ì§€ì‹ ë° ì •ë³´ ì œê³µ ì›ì¹™ (ë§¤ìš° ì¤‘ìš”)]
    1. ì² ì €í•œ ìë£Œ ê¸°ë°˜: ë‹¹ì‹ ì€ ì˜¤ì§ ì•„ë˜ì— ì œê³µëœ 'ì œê³µëœ ìë£Œ(Context)' ë‚´ì—ì„œë§Œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
    2. ê²€ì¦ëœ ì¶œì²˜ ì œí•œ: ì˜í•™ ë° ê°„í˜¸í•™ ì§€ì‹ê³¼ ê´€ë ¨ëœ ë‹µë³€ì€ ì œê³µëœ ìë£Œ ì¤‘ì—ì„œë„ ì¶œì²˜ê°€ ë¶„ëª…í•œ ë²”ìœ„ì˜ ë‚´ìš©ë§Œ ë°”íƒ•ìœ¼ë¡œ ì œê³µí•˜ì‹­ì‹œì˜¤.
    3. ì„ì˜ ì¶”ë¡  ê¸ˆì§€: ì œê³µëœ ìë£Œì— ëª…ì‹œë˜ì–´ ìˆì§€ ì•Šì€ ì‚¬ì‹¤ì„ ìŠ¤ìŠ¤ë¡œ ì¶”ë¡ í•˜ê±°ë‚˜ ì§€ì–´ë‚´ì„œ ë‹µë³€í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.

    [êµê³¼ëª© ë¬¸ì˜ ë° ì˜ˆì™¸/ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì²˜ë¦¬]
    1. êµê³¼ëª© ìš´ì˜ì— ëŒ€í•œ ë¬¸ì˜ëŠ” ì œê³µëœ ìë£Œ ë‚´ì—ì„œë§Œ ë‹µë³€í•˜ì‹­ì‹œì˜¤.
    2. êµìˆ˜ì ì´ê´€(Escalation): ì œê³µëœ ìë£Œì— ë‹µì´ ì—†ê±°ë‚˜ ëª¨í˜¸í•œ ê²½ìš° ë°˜ë“œì‹œ ë‹¤ìŒ ë¬¸êµ¬ë¥¼ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
       "í•´ë‹¹ ë‚´ìš©ì€ ì œê³µëœ ê°•ì˜ ìë£Œì—ì„œ ëª…í™•í•œ í™•ì¸ì´ ì–´ë µê±°ë‚˜, ì¶”ê°€ì ì¸ ì „ë¬¸ì  í•´ì„ì´ í•„ìš”í•©ë‹ˆë‹¤. ì •í™•í•œ í•™ìŠµê³¼ ì„ìƒ ì ìš©ì„ ìœ„í•´ ë‹´ë‹¹ êµìˆ˜ë‹˜ê»˜ ì§ì ‘ ë¬¸ì˜í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤."

    [ë‹µë³€ í˜•ì‹ ê·œì •]
    - ì „ë¬¸ì ì¸ ê°„í˜¸í•™ ìš©ì–´ë¥¼ ì •í™•í•˜ê²Œ ì‚¬ìš©í•˜ë˜, ë¬¸ë§¥ì„ ì‰½ê²Œ í’€ì–´ ì„¤ëª…í•˜ì‹­ì‹œì˜¤.
    - ì°¸ê³ í•œ [ì¶œì²˜: ë¬¸ì„œëª…, í˜ì´ì§€]ë¥¼ ëŒ€ê´„í˜¸ ì•ˆì— ëª…ì‹œí•˜ì‹­ì‹œì˜¤.

    ì œê³µëœ ìë£Œ(Context):
    {context}
    """

    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt),
            ("human", "{input}"),
        ]
    )

    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

    question_answer_chain = create_stuff_documents_chain(llm, prompt)
    rag_chain = create_retrieval_chain(retriever, question_answer_chain)

    return rag_chain


rag_chain = init_rag_pipeline()

# 4. Streamlit ì±„íŒ… UI êµ¬ì„± ë° ë°ì´í„° ì €ì¥ ë¡œì§
if rag_chain is None:
    st.error("âš ï¸ 'data' í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìë£Œë¥¼ ë„£ê³  ìƒˆë¡œê³ ì¹¨ í•´ì£¼ì„¸ìš”.")
else:
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input(
        "ì„±ì¸ê°„í˜¸í•™ì— ëŒ€í•´ ì§ˆë¬¸í•´ ì£¼ì„¸ìš” (ì˜ˆ: íë ´ í™˜ìì˜ ê°„í˜¸ ì¤‘ì¬ëŠ”?)"
    ):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("ìë£Œë¥¼ ê²€ìƒ‰í•˜ê³  ë‹µë³€ì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                response = rag_chain.invoke({"input": prompt})
                answer = response["answer"]
                st.markdown(answer)

                with st.expander("ì°¸ê³ í•œ ë¬¸ì„œ ì¡°ê° í™•ì¸í•˜ê¸°"):
                    for doc in response["context"]:
                        st.write(
                            f"- {doc.metadata['source']} (Page {doc.metadata['page']})"
                        )

        st.session_state.messages.append({"role": "assistant", "content": answer})

        # 5. ì§ˆë¬¸ê³¼ ë‹µë³€ì„ êµ¬ê¸€ ì‹œíŠ¸ì— ìë™ ê¸°ë¡!
        if sheet is not None:
            try:
                kst = pytz.timezone("Asia/Seoul")
                now = datetime.now(kst).strftime("%Y-%m-%d %H:%M:%S")
                sheet.append_row([now, prompt, answer])
            except Exception as e:
                print(f"ì‹œíŠ¸ ì €ì¥ ì—ëŸ¬: {e}")

